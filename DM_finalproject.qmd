---
title: "DM_finalproject"
author: Paula and Esther
format: html
---

## Introduction

The link to our github repository : https://github.com/estal8/Data-management---final-project.git

## Description of our data

The **crime per state (1960-2019) database** from the **CORGIS Dataset Project** (Collection of Really Great, Interesting, Situated Datasets). This dataset was produced by the U.S. Department of Justice and the Federal Bureau of Investigation. The crimes described in this dataset are divided into two categories : violent crimes and property crimes (much more numerous), which encompass themselves different types of crimes : 

- violent crimes : assaults, murders, rapes, and robberies.

- property crimes : burglaries, larcenies, and motor crimes.

The database combines rates per 100 000 population and total number of crimes per states, which we will mainly focus on.

https://corgis-edu.github.io/corgis/csv/state_crime/


The **World Inequality Database** (WID), for every US state. The WID combines national accounts with survey data and tax sources, enabling the publication of more reliable estimates of inequality covering the entire distribution of income and wealth. It was initially created in January 2011 under the name World Top Incomes Database (WTID) and offers the most comprehensive collection of historical series on wealth inequality available to date. We only downloaded data for each US state.

https://wid.world/fr/donnees/


The **police shootings database (2015-2024)** we used is from the Washington Post. In 2015, the Washington Post started compiling data on murders caused by police shootings. The data gathered is much larger than what we need (threat type, flee status, name and age of the victime, etc). We will calculate the number of people who have died because of a police shooting by state.

https://github.com/washingtonpost/data-police-shootings/tree/master 


The **immigration per state database (2013-2023)** is from the Office of Homeland Security of the United States. The tables provide totals for lawful permanent residents (LPRs), new arrivals and adjustments; nonimmigrant arrivals; naturalizations; refugee arrivals; and total asylum grants.

https://ohss.dhs.gov/topics/immigration/state-immigration-data 


The **total per capita categorized public spending** (education, welfare, health, corrections, etc.) **for every US state (2017-2023)** database is from the United States Census Bureau.

https://data.census.gov/table/GOVSTIMESERIES.GS00LF01?q=Local+Government+Finances&g=010XX00US,$0400000&nkd=GOVTYPE~001,time~2023  


The **Food Environment Atlas (2012-2023)** from the **US Department for Agriculture** (USDA). It incorporates data from the Food Access Research Atlas, the Household Food Security in the United States, SNAP Policy Database, Atlas of Rural and Small-Town America, and Poverty Area Measures. 

https://www.ers.usda.gov/data-products/food-environment-atlas/data-access-and-documentation-downloads 


**Regional Economic Accounts** from the **Bureau of Economic Analysis** of the US. We only downloaded the SASUMMARY table, that compiles State Annual Summary Statistics (Personal Income, GDP, Consumer Spending, Price Indexes, and Employment).

https://apps.bea.gov/regional/downloadzip.htm


**State unemployment** ????

Unemployment per state: https://data.bls.gov/cew/apps/table_maker/v4/table_maker.htm#type=0&year=2024&qtr=A&own=2&ind=10&supp=0 or from the census bureau : https://data.census.gov/table/ACSDP1Y2024.DP03?q=employment&g=010XX00US$0400000 


## Data cleaning

Loading the packages we will use and starting cleaning for each base.

```{r}
#| message : false
#| echo : false

library(dplyr)
library(here)
library(vroom)
library(ggplot2)
library(tidyverse)
library(tidyr)
```

```{r}
here::i_am("Data-management---final-project.Rproj")
```

### Loading and cleaning each database

#### The crime database

```{r}
crime <- vroom("DATA_statecrime.csv")
```




#### The WID database

First, we must join all 51 states bases of the WID. To do so, we are going to create a list with all the files' names to avoid having to manually download all of them.

```{r}
codes_states <- c(
 "US-AL", "US-AK", "US-AZ", "US-AR", "US-CA", "US-CO", "US-CT", "US-DE",
 "US-FL", "US-GA", "US-HI", "US-ID", "US-IL", "US-IN", "US-IA", "US-KS",
 "US-KY", "US-LA", "US-ME", "US-MD", "US-MA", "US-MI", "US-MN", "US-MS",
 "US-MO", "US-MT", "US-NE", "US-NV", "US-NH", "US-NJ", "US-NM", "US-NY",
 "US-NC", "US-ND", "US-OH", "US-OK", "US-OR", "US-PA", "US-RI", "US-SC",
 "US-SD", "US-TN", "US-TX", "US-UT", "US-VT", "US-VA", "US-WA", "US-WV",
 "US-WI", "US-WY", "US-DC"
)
```

Here, we recreate the 51 file names.

```{r}
file_names <- here("DATA_wid", paste0("WID_data_", codes_states, ".csv"))
```

Since the files don't have the full state names, we need to turn the abbreviations into the actual states names. To do so, we create a data base that associates each abbreviation to the state.

```{r}
dict_states <- tibble(
 country = c(
   "US-AL", "US-AK", "US-AZ", "US-AR", "US-CA", "US-CO", "US-CT", "US-DE",
   "US-FL", "US-GA", "US-HI", "US-ID", "US-IL", "US-IN", "US-IA", "US-KS",
   "US-KY", "US-LA", "US-ME", "US-MD", "US-MA", "US-MI", "US-MN", "US-MS",
   "US-MO", "US-MT", "US-NE", "US-NV", "US-NH", "US-NJ", "US-NM", "US-NY",
   "US-NC", "US-ND", "US-OH", "US-OK", "US-OR", "US-PA", "US-RI", "US-SC",
   "US-SD", "US-TN", "US-TX", "US-UT", "US-VT", "US-VA", "US-WA", "US-WV",
   "US-WI", "US-WY", "US-DC"
 ),
 State = c(
   "Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado",
   "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho",
   "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana",
   "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota",
   "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada",
   "New Hampshire", "New Jersey", "New Mexico", "New York",
   "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon",
   "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota",
   "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington",
   "West Virginia", "Wisconsin", "Wyoming", "District of Columbia"
 )
)
```

Now, we create a list with all the file names and download all files.

```{r}
list_wid <- list()

list_wid <- lapply(file_names, vroom, delim = ";", show_col_types = FALSE)
```

And now, we can bind the 51 databases by using *bind_rows* so that each of them is stacked below the previous one.

```{r}
wid_all <- bind_rows(list_wid)
```

We check that we have the right number of states.

```{r}
nrow(wid_all)
n_distinct(wid_all$country)
```

We have 51 states because the District of Columbia is counted as one here. The variable is named country because the WID is originally for countries and not for regions within countries.

Now, checking for missing values : 

```{r}
wid_all |>
 summarise(
   na_country = sum(is.na(country)),
   na_variable = sum(is.na(variable)),
   na_percentile = sum(is.na(percentile)),
   na_year = sum(is.na(year)),
   na_value = sum(is.na(value)),
   na_age = sum(is.na(age)),
   na_pop = sum(is.na(pop))
 ) |>
  knitr::kable()
```

There are no missing values.

As for the types : 

```{r}
sapply(wid_all, typeof)
```

**Change the type of year, value and age ???**

We also want to clarify what the variable codes stand for. We use the variable list that was provided when downloading the WID data, and then join the newly created database to our **wid_all** base.

```{r}
dict_variables <- tibble(
 variable = c("afiinct992", "mfiinct992", "npopult992",
              "ntaxret992", "sfiinct992", "sptinct992"),
 new_name = c("avg_fiscal_income", "total_fiscal_income", "population",
               "nb_tax_returns", "share_fiscal_income", "share_pretax_income")
)
```

```{r}
wid_all <- wid_all |>
  left_join(dict_variables, by = "variable") |>
  select(!variable) |>
  left_join(dict_states, by = "country") |>
  select(!country) |>
  relocate(State, new_name)
```

The database now looks like this : 

```{r}
wid_all |>
 slice_head(n = 10) |>
  knitr::kable()
```

The table that summarises this database : 

```{r}
wid_all |>
  summarise(
    nb_lines = n(),
    nb_states = n_distinct(State),
    nb_years = n_distinct(year)
  ) |>
  knitr::kable()
```



